"""Tests for exploitability computation."""

import pytest

from src.abstraction.core.action_abstraction import ActionAbstraction
from src.evaluation.exploitability import compute_exploitability
from src.solver.mccfr import MCCFRSolver
from src.solver.storage import InMemoryStorage
from tests.test_helpers import DummyCardAbstraction


class TestExploitability:
    """Tests for exploitability computation."""

    def test_compute_exploitability_untrained_solver(self):
        """Test exploitability of an untrained solver (should be high)."""
        # Create solver
        action_abstraction = ActionAbstraction()
        card_abstraction = DummyCardAbstraction()
        storage = InMemoryStorage()

        solver = MCCFRSolver(
            action_abstraction,
            card_abstraction,
            storage,
            config={"starting_stack": 200, "small_blind": 1, "big_blind": 2},
        )

        # Compute exploitability with very small sample size for speed (just 10 samples)
        result = compute_exploitability(solver, num_samples=10, use_average_strategy=True)

        # Check result structure
        assert "exploitability_mbb" in result
        assert "player_0_br_utility" in result
        assert "player_1_br_utility" in result

        # Exploitability should be a number
        assert isinstance(result["exploitability_mbb"], float)

        # For untrained solver, exploitability should be relatively high
        # (uniform random play is very exploitable)
        print(f"Untrained exploitability: {result['exploitability_mbb']:.2f} mbb/g")

    @pytest.mark.slow
    @pytest.mark.timeout(20)
    def test_compute_exploitability_trained_solver(self):
        """Test exploitability of a trained solver (should be lower)."""
        # Create solver
        action_abstraction = ActionAbstraction()
        card_abstraction = DummyCardAbstraction()
        storage = InMemoryStorage()

        solver = MCCFRSolver(
            action_abstraction,
            card_abstraction,
            storage,
            config={"starting_stack": 200, "small_blind": 1, "big_blind": 2, "seed": 42},
        )

        # Train for fewer iterations for speed
        for _ in range(30):
            solver.train_iteration()

        # Compute exploitability with small sample
        result = compute_exploitability(solver, num_samples=3, use_average_strategy=True)

        print(f"Trained (30 iters) exploitability: {result['exploitability_mbb']:.2f} mbb/g")

        # After training, exploitability should be a reasonable number
        # Relaxed threshold since we're training less
        assert result["exploitability_mbb"] >= 0
        assert result["exploitability_mbb"] < 50000  # Very loose bound for minimal training

    @pytest.mark.slow
    @pytest.mark.timeout(20)
    def test_compute_exploitability_different_strategies(self):
        """Test that average strategy and current strategy give different results."""
        # Create and train solver
        action_abstraction = ActionAbstraction()
        card_abstraction = DummyCardAbstraction()
        storage = InMemoryStorage()

        solver = MCCFRSolver(
            action_abstraction,
            card_abstraction,
            storage,
            config={"starting_stack": 200, "small_blind": 1, "big_blind": 2, "seed": 42},
        )

        # Train briefly
        for _ in range(15):
            solver.train_iteration()

        # Compute both with small samples
        avg_result = compute_exploitability(solver, num_samples=2, use_average_strategy=True)
        current_result = compute_exploitability(solver, num_samples=2, use_average_strategy=False)

        print(f"Average strategy exploitability: {avg_result['exploitability_mbb']:.2f} mbb/g")
        print(f"Current strategy exploitability: {current_result['exploitability_mbb']:.2f} mbb/g")

        # Both should be valid numbers
        assert avg_result["exploitability_mbb"] >= 0
        assert current_result["exploitability_mbb"] >= 0
