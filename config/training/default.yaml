# Default Configuration Template for HUNLHE Solver
# Heads-Up No-Limit Hold'em Monte Carlo CFR Solver
#
# This file shows ALL configurable options with explanations.
# All values are COMMENTED OUT to use Python defaults from src/utils/config.py
# Uncomment and modify only what you need to change.

# ===== Game Configuration =====
# game:
#   starting_stack: 200  # BB units (default: 200)
#   small_blind: 1       # (default: 1)
#   big_blind: 2         # (default: 2)

# ===== Action Model =====
# action_model:
#   # Preflop templates by node type (HU-only)
#   # preflop_templates:
#   #   sb_first_in: ["fold", "call", 2.0, 2.5]
#   #   bb_vs_open: ["fold", "call", "3.5x_open", "4.5x_open"]
#
#   # Postflop templates by context
#   # postflop_templates:
#   #   first_aggressive: [0.33, 0.75, 1.25, "jam_low_spr"]
#   #   facing_bet: ["min_raise", "pot_raise", "jam"]
#   #   after_one_raise: ["pot_raise", "jam"]
#   #   after_two_raises: ["jam"]
#
#   # SPR buckets used by templates like jam_low_spr
#   # jam_spr_threshold: 2.0
#   # off_tree_mapping: "probabilistic"
#
# resolver:
#   # enabled: true
#   # time_budget_ms: 300
#   # max_depth: 2
#   # max_raises_per_street: 4
#   # leaf_value_mode: "blueprint_rollout"

# ===== Card Abstraction =====
# card_abstraction:
#   # Reference to precomputed abstraction config
#   # config: default  # default: "default"
#   # Or use direct file path:
#   # abstraction_path: "data/combo_abstraction/combo-20251220-120000/combo_abstraction.pkl"

# ===== Solver Configuration =====
# solver:
#   # Sampling method options:
#   # - "external": Lower variance, slower (recommended for production)
#   # - "outcome": Higher variance, faster (good for testing)
#   # sampling_method: "external"  # default: "external"
#
#   # CFR+ provides ~100x faster convergence than vanilla CFR
#   # cfr_plus: true  # default: true
#
#   # Linear CFR provides additional 2-3x speedup
#   # linear_cfr: true  # default: true

# ===== Training Configuration =====
# training:
#   # num_iterations: 100000           # Total iterations (default: 100_000)
#   # checkpoint_frequency: 50000      # Save every N iterations (default: 50_000)
#   # iterations_per_worker: 1000      # Batch size multiplier for parallel (default: 1_000)
#   # verbose: true                    # Show verbose output (default: true)
#   # runs_dir: "data/runs"            # Output directory (default: "data/runs")

# ===== Storage Configuration =====
# storage:
#   # checkpoint_enabled: true         # Save periodic checkpoints (default: true, recommended)
#   # initial_capacity: 2000000        # Initial infosets capacity (default: 2_000_000, grows automatically)
#   # max_actions: 10                  # Max actions per infoset (default: 10)
#
#   # Zarr checkpoint compression (used since 2026-01-18)
#   # zarr_compression_level: 3        # ZStd level (default: 3)
#   #   - Level 1: Fastest I/O, larger files (~270MB for 2M infosets)
#   #   - Level 3: Balanced (5.6x faster than old NPZ, 163MB for 2M infosets)
#   #   - Level 5: Smaller files, slower writes (161MB for 2M infosets)
#   # zarr_chunk_size: 10000           # Infosets per chunk (default: 10_000)
#   #   - Larger chunks (50K-100K): Fewer files, faster loading
#   #   - Smaller chunks (10K): Better for partial reads

# ===== System Configuration =====
# system:
#   # config_name: "default"           # Name of this config (default: "default")
#   # seed: null                       # Random seed (default: null = random each run)
#   # log_level: "INFO"                # Options: DEBUG, INFO, WARNING, ERROR (default: "INFO")
